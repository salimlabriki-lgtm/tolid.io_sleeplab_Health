services:
  postgres:
    image: postgres:16
    container_name: sleeplab-postgres
    environment:
      POSTGRES_USER: sleeplab
      POSTGRES_PASSWORD: sleeplab
      POSTGRES_DB: sleeplab
    ports:
      - "5432:5432"
    volumes:
      - ./db/data:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d
    restart: unless-stopped

  etl:
    image: python:3.11-slim
    depends_on:
      postgres:
        condition: service_healthy
    working_dir: /app
    environment:
      DB_DSN: postgresql://postgres:postgres@postgres:5432/sleeplab
    volumes:
      - ./etl:/app
    command: bash -lc "pip install -r requirements.txt && pytest -q && python app/etl_demo.py && echo 'ETL done'"

  superset:
    image: apache/superset:latest
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      SUPERSET_SECRET_KEY: "please_change_me"
      SUPERSET_ADMIN: "admin"
      SUPERSET_PASSWORD: "admin"
      DB_HOST: "postgres"              # pour le wait
    volumes:
      - ./superset/bootstrap.sh:/app/bootstrap.sh:ro
    ports:
      - "8088:8088"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8088/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
    command: ["/bin/bash","-lc","/app/bootstrap.sh"]
  
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped

    # ---- Ports exposés ----
    ports:
      - "${OLLAMA_PORT:-11434}:11434"    # API HTTP Ollama (localhost:11434)

    # ---- Variables d'environnement ----
    environment:
      - OLLAMA_KEEP_ALIVE=24h            # garde les modèles chargés 24h
      # - OLLAMA_NOPULL=1                # (optionnel) bloque les pulls automatiques

    # ---- Volume pour persister les modèles téléchargés ----
    volumes:
      - ollama_models:/root/.ollama

    # ---- Healthcheck pour attendre l'API ----
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:11434/api/tags || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12

    # ---- GPU (optionnel, seulement si machine NVIDIA configurée) ----
    # profiles: ["gpu"]
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - capabilities: ["gpu"]


volumes:
  pgdata:
  ollama_models:
